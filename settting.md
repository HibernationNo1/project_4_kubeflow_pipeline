

`Ubuntu 18.04`



## install

### requirements

1. **install NVIDIA driver**

   ```
   $ nvidia-smi
   ```

   



### docker

[ê³µì‹ ë¬¸ì„œ](https://docs.docker.com/engine/install/ubuntu/)

**Install using the repository**

1. install dockerì˜ prerequisite packge

   ```
   $ sudo apt-get install \
       ca-certificates \
       curl \
       gnupg \
       lsb-release
   ```

   

2. GPH keyì¶”ê°€

   ```
   $ sudo mkdir -p /etc/apt/keyrings
   $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
   ```

   

3. repositoryë¥¼ followí•˜ë„ë¡ ì„¤ì •

   ```
   $ echo \
     "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
     $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
   ```

   > armê¸°ë°˜ì˜ cpuì¸ ê²½ìš° ìœ„ ëª…ë ¹ì–´ ëŒ€ì‹  ë‹¤ë¥¸ ëª…ë ¹ì–´ ì‚¬ìš©(ê²€ìƒ‰í•˜ê¸°)

   

4. install Docker Engine (ìµœì‹  version)

   ```
   $ sudo apt-get update
   $ sudo apt-get install docker-ce docker-ce-cli containerd.io
   ```

   > íŠ¹ì • versionì˜ docker engineì„ installí•˜ê³ ì í•œë‹¤ë©´ ê³µì‹ ë¬¸ì„œ ì°¸ê³ 

5. Create required directories

   ```
   $ sudo mkdir -p /etc/systemd/system/docker.service.d
   ```

   

6. Create daemon json config file

   ```
   $ sudo tee /etc/docker/daemon.json <<EOF
   {
     "exec-opts": ["native.cgroupdriver=systemd"],
     "log-driver": "json-file",
     "log-opts": {
       "max-size": "100m"
     },
     "storage-driver": "overlay2"
   }
   EOF
   ```

   ```
   $ sudo systemctl daemon-reload 
   ```

   

7. check

   ```
   $ sudo docker run hello-world
   ```

   `Hello from Docker!` ì´ í¬í•¨ëœ ì¶œë ¥ë¬¸ì´ ë‚˜ì˜¤ë©´ ëœê²ƒ

   

8. ê¶Œí•œ ì„¤ì •

   root userê°€ ì•„ë‹Œ, hostì˜ ê¸°ë³¸ userì—ê²Œë„ ê¶Œí•œì„ ì£¼ê¸° ìœ„í•´ 

   ìƒˆë¡œìš´ í„°ë¯¸ë„ ë„ìš´ í›„ 

   ```
   $ sudo usermod -a -G docker $USER
   $ sudo systemctl restart docker
   $ sudo systemctl enable docker
   ```

   ì´í›„ logout(ë˜ëŠ” reboot)í›„ ë‹¤ì‹œ login

   ```
   $ docker ps
   ```

   

#### Install Mirantis cri-dockerd

[ê³µì‹ ë¬¸ì„œ](https://computingforgeeks.com/install-mirantis-cri-dockerd-as-docker-engine-shim-for-kubernetes/)

Docker ì—”ì§„ì˜ ê²½ìš° shim ì¸í„°í˜ì´ìŠ¤ê°€ í•„ìš”

Kubernetesìš© Docker Engine shimìœ¼ë¡œ **Mirantis cri-dockerd** ì„¤ì¹˜

> Kubernetesê°€ v1.20 ì´í›„ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ìœ¼ë¡œ Dockerë¥¼ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ Docker ìƒì„± ì´ë¯¸ì§€ëŠ” í•­ìƒ ê·¸ë˜ì™”ë“¯ì´ ëª¨ë“  ëŸ°íƒ€ì„ê³¼ í•¨ê»˜ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ ê³„ì† ì‘ë™ëœë‹¤.
>
> **cri-dockerd**ë¥¼ ì‚¬ìš©í•˜ë©´ Docker ì—”ì§„ì´ CRIë¥¼ ì¤€ìˆ˜í•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ë³¸ ì œê³µ dockershimì—ì„œ ì™¸ë¶€ dockershimìœ¼ë¡œ ì „í™˜í•˜ê¸°ë§Œ í•˜ë©´ Kubernetesì—ì„œ ê³„ì† ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

Mirantis cri-dockerd CRI ì†Œì¼“ íŒŒì¼ ê²½ë¡œëŠ” `/run/cri-dockerd.sock` (Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•  ë•Œ ì‚¬ìš©)

1. get the latest release version

   ```
   $ VER=$(curl -s https://api.github.com/repos/Mirantis/cri-dockerd/releases/latest|grep tag_name | cut -d '"' -f 4|sed 's/v//g')
   $ echo $VER
   ```

2. download the archive file from [Github cri-dockerd releases](https://github.com/Mirantis/cri-dockerd/releases) page.

   ```
   $ wget https://github.com/Mirantis/cri-dockerd/releases/download/v${VER}/cri-dockerd-${VER}.amd64.tgz
   tar xvf cri-dockerd-${VER}.amd64.tgz
   ```

   Move `cri-dockerd` binary package to `/usr/local/bin` directory

   ```
   $ sudo mv cri-dockerd/cri-dockerd /usr/local/bin/
   ```

3. Validate successful installation

   ```
   $ cri-dockerd --version
   ```

   ```
   cri-dockerd 0.2.5 (10797dc)
   ```

4. Configure systemd

   ```
   $ wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.service
   $ wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.socket
   $ sudo mv cri-docker.socket cri-docker.service /etc/systemd/system/
   $ sudo sed -i -e 's,/usr/bin/cri-dockerd,/usr/local/bin/cri-dockerd,' /etc/systemd/system/cri-docker.service
   ```

5. Start and enable the services

   ```
   $ sudo systemctl daemon-reload
   $ sudo systemctl enable cri-docker.service
   $ sudo systemctl enable --now cri-docker.socket
   ```

6. Confirm the service is now running

   ```
   $ systemctl status cri-docker.socket
   ```

   ```
   â— cri-docker.socket - CRI Docker Socket for the API
        Loaded: loaded (/etc/systemd/system/cri-docker.socket; enabled; vendor preset: enabled)
        Active: active (listening) since Tue 2022-09-20 14:01:38 KST; 11s ago
      Triggers: â— cri-docker.service
        Listen: /run/cri-dockerd.sock (Stream)
         Tasks: 0 (limit: 76823)
        Memory: 116.0K
        CGroup: /system.slice/cri-docker.socket
   
   Sep 20 14:01:38 ubuntu systemd[1]: Starting CRI Docker Socket for the API.
   Sep 20 14:01:38 ubuntu systemd[1]: Listening on CRI Docker Socket for the API.
   ```

   

#### NVIDIA DOCKER

docker contianerì•ˆì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  í•„ìˆ˜

1. Setting up NVIDIA Container Toolkit

   ```
   $ distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
         && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
         && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
               sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
               sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
   ```

   > `ubuntu18.04/$(ARCH)` ë– ë„ 20.04ì—ì„œ ì •ìƒ ì‘ë™

2. install nvidia-docker2

   ```
   $ sudo apt-get update
   $ sudo apt-get install -y nvidia-docker2
   ```

   ```
   *** daemon.json (Y/I/N/O/D/Z) [default=N] ? y
   Installing new version of config file /etc/docker/daemon.json ...
   ```

3. Restart the Docker daemon 

   ```
   $ sudo systemctl restart docker
   ```

   

   confirm : ê¸°ë³¸ CUDA container ì‹¤í–‰

   ```
   $ sudo docker run --rm --gpus all nvidia/cuda:11.3.1-base-ubuntu20.04 nvidia-smi
   ```

   > cudaì™€ ubuntu versionì— ëŒ€í•œtagëŠ” [docker hub-nvidia](https://hub.docker.com/r/nvidia/cuda/tags)ì—ì„œ ê²€ìƒ‰ í›„ ê²°ì •

4. edit daemon

   ```
   $ sudo vi /etc/docker/daemon.json
   ```

   ì•„ë˜ë‚´ìš© ì¶”ê°€

   ```
   {
     "default-runtime": "nvidia",
     "runtimes": {
       "nvidia": {
         "path": "nvidia-container-runtime",
         "runtimeArgs": []
       }
     }
   }
   ```

   ```
   $ sudo systemctl daemon-reload 
   ```

   

   



### minikube

[ê³µì‹](https://minikube.sigs.k8s.io/docs/start/)

CPU 2core ì´ìƒ, Memory 2GBì´ìƒ, Disk : 20GBì´ìƒ

```
$ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
$ sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

check

```
$ minikube version
```



#### kubectl

[ê³µì‹](https://kubernetes.io/ko/docs/tasks/tools/install-kubectl-linux/)

íŠ¹ì • release ë‹¤ìš´ë¡œë“œ(1.20.13) (releaseí™•ì¸ì€ [ì—¬ê¸°](https://kubernetes.io/releases/) ì—ì„œ)

```
$ sudo curl -LO https://dl.k8s.io/release/v1.22.13/bin/linux/amd64/kubectl
```

ë°”ì´ë„ˆë¦¬ ê²€ì¦

```
$ curl -LO "https://dl.k8s.io/v1.22.13/bin/linux/amd64/kubectl.sha256"
$ echo "$(<kubectl.sha256)  kubectl" | sha256sum --check
```

> ê²€ì¦ ì„±ê³µì‹œ ì•„ë˜ì²˜ëŸ¼ ì¶œë ¥
>
> ```
> kubectl: OK
> ```

install kubectl

```
$ sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
```

check

```
$ kubectl version --client
```

> ```
> Client Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.2", GitCommit:"f66044f4361b9f1f96f0053dd46cb7dce5e990a8", GitTreeState:"clean", BuildDate:"2022-06-15T14:22:29Z", GoVersion:"go1.18.3", Compiler:"gc", Platform:"linux/amd64"}
> ```
>
> ìœ„ ì²˜ëŸ¼ ë– ë„ ì •ìƒ (kubenetes serverì™€ clientì˜ versionì´ ëª¨ë‘ ì¶œë ¥í•˜ëŠ” ê³¼ì •ì—ì„œ, hostì—ì„œ kubenetes serverë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ëœ¨ëŠ” ë¬¸êµ¬)
>
> - `bash: /usr/bin/kubectl: No such file or directory` ë¼ëŠ” ë¬¸êµ¬ê°€ ëœ¨ë©´
>
>   ```
>   $ bash
>   ```
>   
>   ë˜ëŠ” ìƒˆ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
>





#### start minikube

confirm host

```
$ sudo vim /etc/hosts
```

ì•„ë˜ ë‘ ê°œê°€ ì œëŒ€ë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸

```
127.0.0.1       host.minikube.internal
192.168.0.107   control-plane.minikube.internal
```



```
$ minikube start --driver=none \
  --kubernetes-version=v1.22.13 \
  --extra-config=apiserver.service-account-signing-key-file=/var/lib/minikube/certs/sa.key \
  --extra-config=apiserver.service-account-issuer=kubernetes.default.svc
```

- `--kubernetes-version ` : kubectl ì„¤ì¹˜ ì‹œ íŠ¹ì •í•œ version
- `--extra-config=apiserver.service-account-signing-key-file=/var/lib/minikube/certs/sa.key` : kubeflowë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ flag
- `--extra-config=apiserver.service-account-issuer=kubernetes.default.svc`  : kubeflowë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ flag

> error
>
> - ```
>   Exiting due to PROVIDER_NONE_NOT_FOUND: The 'none' provider was not found: running the 'none' driver as a regular user requires sudo permissions
>   ```
>
>   sudo ë¶™ì—¬ì„œ ì‹¤í–‰
>
> - ```
>   Exiting due to HOST_JUJU_LOCK_PERMISSION: Failed to save config: failed to acquire lock for /home/ainsoft/.minikube/profiles/minikube/config.json: {Name:mk2998bbe62a1ef4b160001f97b8d3cac88d028d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}: unable to open /tmp/juju-mk2998bbe62a1ef4b160001f97b8d3cac88d028d: permission denied
>   ```
>
>   í•´ê²°ë°©ë²• 
>
>   ```
>   $ sudo rm -rf /tmp/juju-mk*
>   $ sudo rm -rf /tmp/minikube.*
>   ```
>
>   



check

```
$ minikube status
```

```
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```



```
$ kubectl get namespace
```

> error
>
> ```
> error: unable to read client-key /home/ainsoft/.minikube/profiles/minikube/client.key for minikube due to open /home/ainsoft/.minikube/profiles/minikube/client.key: permission denied
> ```
>
> í•´ê²°ë°©ë²• : ê¶Œí•œ ì„¤ì •
>
> ```
> sudo chown -R $HOME/.minikube
> ```
>
> ì´ë˜ë„ ì•ˆë˜ë©´
>
> ```
> sudo chown -R $USER $HOME/.kube
> ```
>
> ë„ ì¶”ê°€

```
kubectl get pods -A
```



#### nvidia-device-plugin

1. install

   ```
   $ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/master/nvidia-device-plugin.yml
   ```

   

   check

   ```
   $ kubectl get pod -A | grep nvidia
   ```

   > ```
   > kube-system   nvidia-device-plugin-daemonset-rs69d   1/1     Running   0          48s
   > ```

   

   ```
   $ kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
   ```

   > ```
   > NAME     GPU
   > ubuntu   1
   > ```
   >
   > ìœ„ ì²˜ëŸ¼ 1ì´ ë³´ì—¬ì•¼ í•œë‹¤. (ëª‡ ì´ˆ ê°€ëŸ‰ ì§€ë‚˜ì•¼í•¨)

2. check use GPU at pod

   create pod

   ```
   $ vi gpu-container.yaml
   ```

   ```
   apiVersion: v1
   kind: Pod
   metadata:
     name: gpu
   spec:
     containers:
     - name: gpu-container
       image: nvidia/cuda:11.3.1-runtime-ubuntu20.04
       command:
         - "/bin/sh"
         - "-c"
       args:
         - nvidia-smi && tail -f /dev/null
       resources:
         requests:
           nvidia.com/gpu: 1
         limits:
           nvidia.com/gpu: 1
   ```

   - `nvidia/cuda:10.2-runtime` : ì•Œë§ëŠ” cuda versionëª…ì‹œí•´ì¤˜ì•¼ í•¨
   - ``spec.resources.requests` ì™€ `spec.resources.limits` ì— `nvidia.com/gpu` ë¥¼ í¬í•¨í•´ì•¼ pod ë‚´ì—ì„œ GPU ì‚¬ìš©ì´ ê°€ëŠ¥` â˜…â˜…â˜…

   ```
   $ kubectl create -f gpu-container.yaml
   $ kubectl get pod gpu -n default
   ```
   
   ```
   NAME   READY   STATUS              RESTARTS   AGE
   gpu    0/1     ContainerCreating   0          90s
   ```
   
   > `STATUS : Runniing` í™•ì¸ í›„ ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰
   
   ```
   $ kubectl logs gpu
   ```
   
   
   
   ```
   Thu Aug 25 00:45:45 2022       
   +-----------------------------------------------------------------------------+
   | NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
   |-------------------------------+----------------------+----------------------+
   | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
   | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
   |===============================+======================+======================|
   |   0  GeForce RTX 208...  On   | 00000000:01:00.0 Off |                  N/A |
   |  0%   40C    P8    12W / 300W |   2672MiB / 11019MiB |      0%      Default |
   +-------------------------------+----------------------+----------------------+
                                                                                  
   +-----------------------------------------------------------------------------+
   | Processes:                                                       GPU Memory |
   |  GPU       PID   Type   Process name                             Usage      |
   |=============================================================================|
   +-----------------------------------------------------------------------------+
   ```



### kubeflow

#### **kustomize** 

[ì—¬ê¸°](https://github.com/kubernetes-sigs/kustomize/) ì—ì„œ í˜„ì¬ k8s versionì— ë§ëŠ” kustomize versionì„ í™•ì¸í•˜ê³  download binary

```
$ kubectl version
```

> kustomize 3.2.0ì— ì•Œë§ëŠ” versioní™•ì¸

[ì—¬ê¸°](https://github.com/kubernetes-sigs/kustomize/releases/tag/v3.2.0)ì˜ **Asset** ì•„ë˜ `kustomize_3.2.0_darwin_amd64` ì˜ ë§í¬ ë³µì‚¬ (armì´ë©´ armêº¼ ë³µì‚¬)

> ë§í¬ ì—†ì–´ì§€ë©´ [releases](https://github.com/kubernetes-sigs/kustomize/releases?page) ì—ì„œ 3.2.0 ì°¾ì€ í›„ ì§„í–‰

```
$ sudo wget https://github.com/kubernetes-sigs/kustomize/releases/download/v3.2.0/kustomize_3.2.0_linux_amd64
```

> - 4.2.0 ì„¤ì¹˜ ì‹œ (**ì•„ì§ê¹Œì§„  kubeflowê°€ 3.2.0ì™¸ì˜ versionê³¼ëŠ” í˜¸í™˜ë˜ì§€ ì•Šê³  ìˆìŒ**)
>
>   releasesì—ì„œ 4.2.0ì°¾ì€ í›„ `kustomize_v4.2.0_linux_amd64.tar.gz` ë³µì‚¬ 
>
>   ```
>   sudo wget https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv4.2.0/kustomize_v4.2.0_linux_amd64.tar.gz
>   ```
>
>   
>
>   ì••ì¶• í’€ê³  ì§„í–‰
>
>   ```
>   $ gzip -d kustomize_v4.2.0_linux_amd64.tar.gz
>   $ tar -xvf kustomize_v4.2.0_linux_amd64.tar
>   ```

fileì˜ mode ë³€ê²½ (ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)

```
$ sudo chmod +x kustomize_3.2.0_linux_amd64
```

ì••ì¶• í’€ê³  fileìœ„ì¹˜ ë³€ê²½

```
$ sudo mv kustomize_3.2.0_linux_amd64 /usr/local/bin/kustomize
```

check(ìƒˆ terminal ì—´ê³ )

```
$ kustomize version
```

```
Version: {KustomizeVersion:3.2.0 GitCommit:a3103f1e62ddb5b696daa3fd359bb6f2e8333b49 BuildDate:2019-09-18T16:26:36Z GoOs:linux GoArch:amd64}
```

> uninstall : `sudo rm /usr/local/bin/kustomize`
>
> - 4.2.0ì„¤ì¹˜ ì‹œ `kustomize_3.2.0_linux_amd64` ë¼ëŠ” file ëŒ€ì‹  `kustomize` ë¼ëŠ” file ì¡´ì¬
>
>   ```
>   $ sudo chmod +x kustomize
>   $ sudo mv kustomize /usr/local/bin/kustomize
>   $ kustomize version
>   ```





#### **kubeflow**

1. git clone [kubeflow/manifests](https://github.com/kubeflow/manifests)

   ```
   $ cd ~/hibernation			# git cloneí•  ì„ì˜ì˜ ìœ„ì¹˜
   $ git clone https://github.com/kubeflow/manifests.git
   $ cd manifests
   ```

   > ```
   > $ git checkout tags/v1.4.0 
   > ```
   >
   > ìœ„ ëª…ë ¹ì–´ë¥¼ í†µí•´ íŠ¹ì • versionìœ¼ë¡œ checkoutí•˜ë©´ `manifests/apps/pipeline/upstream/env/` ì˜ cert-manager dirì´ ì‚¬ë¼ì§€ëŠ”  í˜„ìƒ ë°œìƒ 

   1. automatically install

      ```
      $ while ! kustomize build example | kubectl apply -f -; do echo "Retrying to apply resources"; sleep 10; done
      ```

   2. manually install

      kubeflowì˜ individual components install ([github](https://github.com/kubeflow/manifests) ì— ë‹¤ ìˆìŒ. ê°€ëŠ¥í•˜ë©´ í•´ë‹¹ linkì—ì„œ ë³´ê³  install)

      > ê°ê° yaml fileì„ buildì´í›„ kubectl apply -fë¥¼ ì§„í–‰í•˜ê²Œ ë˜ëŠ”, ì´ëŠ” ëª¨ë‘ ìˆœì„œëŒ€ë¡œ í•´ì•¼í•œë‹¤. íŠ¹ì • kubeflow versionì„ ì„¤ì¹˜í•œë‹¤ë©´, ëŒ€í•œ versionì— ëŒ€í•œ tagë¡œ ì´ë™í•˜ì—¬ í•´ë‹¹ versionì— ë§ëŠ” ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì•¼ í•œë‹¤.

      1. cert-manager

         ```
         $ kustomize build common/cert-manager/cert-manager/base | kubectl apply -f -
         $ kustomize build common/cert-manager/kubeflow-issuer/base | kubectl apply -f -
         ```

         check

         ```
         $ kubectl get pod -n cert-manager
         ```

      2. istio

         ```
         $ kustomize build common/istio-1-14/istio-crds/base | kubectl apply -f -
         $ kustomize build common/istio-1-14/istio-namespace/base | kubectl apply -f -
         $ kustomize build common/istio-1-14/istio-install/base | kubectl apply -f -
         ```

         > kubeflow versionì— ë”°ë¼ istioì˜ versionì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸í•  ê²ƒ

         ```
         $ kubectl get pod -n istio-system 
         ```

      3. Dex

         ```
         $ kustomize build common/dex/overlays/istio | kubectl apply -f -
         ```

      4. OIDC AuthService

         ```
         $ kustomize build common/oidc-authservice/base | kubectl apply -f -
         ```

      5. Knative

         > ì„¤ì¹˜ ì•ˆë¨ 
         >
         > ```
         > unable to recognize "STDIN": no matches for kind "PodDisruptionBudget" in version "policy/v1"
         > unable to recognize "STDIN": no matches for kind "PodDisruptionBudget" in version "policy/v1"
         > ```
         >
         > 

         ```
         $ kustomize build common/knative/knative-serving/overlays/gateways | kubectl apply -f -
         $ kustomize build common/istio-1-14/cluster-local-gateway/base | kubectl apply -f -
         ```

      6. Kubeflow Namespace

         ```
         $ kustomize build common/kubeflow-namespace/base | kubectl apply -f -
         ```

         check

         ```
         $ kubectl get namespace   # Kubeflowë¼ëŠ” namespaceìƒì„±ë˜ì–´ì•¼í•¨
         ```

      7. Kubeflow Roles

         ```
         $ kustomize build common/kubeflow-roles/base | kubectl apply -f -
         ```

      8. Kubeflow Istio Resources

         ```
         $ kustomize build common/istio-1-14/kubeflow-istio-resources/base | kubectl apply -f -
         ```

         > kubeflow versionì— ë”°ë¼ istioì˜ versionì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸í•  ê²ƒ

      9. Kubeflow Pipelines

         ```
         $ kustomize build apps/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user | kubectl apply -f -
         ```

         > If your container runtime is not docker, use pns executor instead:
         >
         > ```
         > $ kustomize build apps/pipeline/upstream/env/platform-agnostic-multi-user-pns | kubectl apply -f -
         > ```

         ë§Œì•½ ì•„ë˜ì™€ ê°™ì€ errorê°€ ë–³ë‹¤ë©´

         ```
         unable to recognize "STDIN": no matches for kind "CompositeController" in version "metacontroller.k8s.io/v1alpha1"
         ```

         ìœ„ ì„¤ì¹˜ ëª…ë ¹ì–´ ë‹¤ì‹œ ì…ë ¥

      10. KServe

          Install the KServe component

          ```
          $ kustomize build contrib/kserve/kserve | kubectl apply -f -
          ```

          > ```
          > anable to recognize "STDIN": no matches for kind "ClusterServingRuntime" in version "serving.kserve.io/v1alpha1"
          > ```
          >
          > ê°€ ëœ¬ë‹¤ë©´ ìœ„ ëª…ë ¹ì–´ í•œë²ˆ ë” ì…ë ¥

          Install the Models web app

          ```
          $ kustomize build contrib/kserve/models-web-app/overlays/kubeflow | kubectl apply -f -
          ```

      11. Katib

          ```
          $ kustomize build apps/katib/upstream/installs/katib-with-kubeflow | kubectl apply -f -
          ```

      12. Central Dashboard

          ```
          $ kustomize build apps/centraldashboard/upstream/overlays/kserve | kubectl apply -f -
          ```

      13. Admission Webhook

          ```
          $ kustomize build apps/admission-webhook/upstream/overlays/cert-manager | kubectl apply -f -
          ```

      14. Notebooks

          Install the Notebook Controller official Kubeflow component

          ```
          $ kustomize build apps/jupyter/notebook-controller/upstream/overlays/kubeflow | kubectl apply -f -
          ```

          Install the Jupyter Web App official Kubeflow component

          ```
          # kustomize build apps/jupyter/jupyter-web-app/upstream/overlays/istio | kubectl apply -f -
          ```

      15. Profiles + KFAM

          ```
          $ kustomize build apps/profiles/upstream/overlays/kubeflow | kubectl apply -f -
          ```

      16. Volumes Web App

          ```
          $ kustomize build apps/volumes-web-app/upstream/overlays/istio | kubectl apply -f -
          ```

      17. Tensorboard

          Install the Tensorboards Web App official Kubeflow component

          ```
          $ kustomize build apps/tensorboard/tensorboards-web-app/upstream/overlays/istio | kubectl apply -f -
          ```

          Install the Tensorboard Controller official Kubeflow component

          ```
          $ kustomize build apps/tensorboard/tensorboard-controller/upstream/overlays/kubeflow | kubectl apply -f -
          ```

      18. training operator

          ```
          $ kustomize build apps/training-operator/upstream/overlays/kubeflow | kubectl apply -f -
          ```

      19. User Namespace

          ```
          $kustomize build common/user-namespace/base | kubectl apply -f -
          ```

      

2. ëª¨ë“  pod êµ¬ë™

   ```
   $ kubectl get po -A -w
   ```

   > ê¸¸ê²ŒëŠ” ëª‡ì‹­ë¶„ê¹Œì§€ ê±¸ë¦¼







## add user

dashboardì— userë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ì„œëŠ” cm dexë¥¼ ìˆ˜ì •í•´ì•¼ í•œë‹¤.

1. **check dex**

   dexëŠ” namespace authì— ìˆìŒ

   ```
   $ kubectl -n auth get cm dex -o yaml
   ```

   ```yaml
   apiVersion: v1
   data:
     config.yaml: |
       issuer: http://dex.auth.svc.cluster.local:5556/dex
       storage:
         type: kubernetes
         config:
           inCluster: true
       web:
         http: 0.0.0.0:5556
       logger:
         level: "debug"
         format: text
       oauth2:
         skipApprovalScreen: true
       enablePasswordDB: true
       staticPasswords:
       - email: user@example.com
         hash: $2y$12$4K/VkmDd1q1Orb3xAt82zu8gk7Ad6ReFR4LCP9UeYE90NLiN9Df72
         # https://github.com/dexidp/dex/pull/1601/commits
         # FIXME: Use hashFromEnv instead
         username: user
         userID: "15841185641784"
       staticClients:
       # https://github.com/dexidp/dex/pull/1664
       - idEnv: OIDC_CLIENT_ID
         redirectURIs: ["/login/oidc"]
         name: 'Dex Login Application'
         secretEnv: OIDC_CLIENT_SECRET
   ... ì´í•˜ ìƒëµ
   
   ```

   ìœ„ì˜ `staticPasswords` ì— ì•„ë˜ 4ê°€ì§€ë¥¼ ì¶”ê°€í•´ì•¼ í•œë‹¤.

   ```
   - email: winter4958@gmail.com
     hash: $2a$12$lRDeywzDl4ds0oRR.erqt.b5fmNpvJb0jdZXE0rMNYdmbfseTzxNW
     userID: "taeuk"
     username: taeuk
   ```

   - `email` : dashdoardì ‘ì†ì‹œ ì…ë ¥í•  email

   - `hash` : dashdoardì ‘ì†ì‹œ ì…ë ¥í•  passward

     > [BCrypt Hash Generator](https://bcrypt-generator.com/) ì—ì„œ hashê°’ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

   - `userID`, `username` : userì •ë³´

2. **add user information**

   ```
   $ kubectl -n auth edit cm dex
   ```

   >  vim editerë¡œ ë³€ê²½

3. **rollout restart**

   dex manifastë¥¼ ìˆ˜ì •í•˜ê³  ë‚œ í›„ í•´ë‹¹ resourceë¥¼ restartí•´ì£¼ì–´ì•¼ í•œë‹¤.

   ```
   $ kubectl rollout restart deployment dex -n auth
   ```

4. **create namespace**

   ì´í›„ í•´ë‹¹ ID/PWë¡œ ì ‘ì†ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, namespaceê°€ ì§€ì •ë˜ì§€ ì•Šì•„ ìì› ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤. 

   ì´ë¥¼ ìœ„í•´ namespaceë¥¼ ìƒì„±í•˜ì

   1. add profile

      ```
      $ vi profile.yaml
      ```

      ```yaml
      #profile.yaml
      apiVersion: kubeflow.org/v1beta1
      kind: Profile
      metadata:
        name: testuser
      spec:
        owner:
          kind: User
          name: winter4958@gmail.com
        resourceQuotaSpec: {}
      ```

      - `metadata.name` : kubeflow pipelineì—ì„œ ì‚¬ìš©í•  namesapceì˜ name

      - `spec.owner`

        - `kind` : Userë¡œ ê³ ì •
        - `name` : ìœ„ dex resourceì— ì¶”ê°€í•œ Userì˜ email

      - `resourceQuotaSpec` : í•´ë‹¹ namesapceì˜ resource í• ë‹¹ëŸ‰ ì œí•œ (optional)

        ```
          resourceQuotaSpec:
            hard:
              cpu: "2"
              memory: 2Gi
              persistentvolumeclaims: "1"
              requests.nvidia.com/gpu: "1"
              requests.storage: "10Gi"
        ```

        - `cpu: "2"` : cpuì œí•œ 2ê°œ

        - `memory` : ë©”ëª¨ë¦¬ ì œí•œ 2 ê¸°ê°€

        - `requests.nvidia.com/gpu` : ì‚¬ìš© ê°€ëŠ¥í•­ GPUì œí•œ 1ê°œ

        - `persistentvolumeclaims` : volume 1ê°œ

        - `requests.storage` : ì €ì¥ì†Œ ê³µê°„ ì œí•œ 10GB

          > resourceQuotaSpecì— ìœ„ ì²˜ëŸ¼ íŠ¹ì • ê°’ì„ ë„£ìœ¼ë©´ ì•„ë˜ì˜ ì—ëŸ¬ê°€ ë°œìƒ
          >
          > ```
          > This step is in Error state with this message: task 'hibernation-project-9kj4p.set-config' errored: pods "hibernation-project-9kj4p-3036383870" is forbidden: failed quota: kf-resource-quota: must specify cpu,memory
          > ```

   2. apply

      ```
      $ kubectl apply -f profile.yaml
      ```

   3. edit

      profile ë³€ê²½ì´ í•„ìš”í•  ì‹œ

      ```
      $ kubectl edit profile <namespace_name>
      ```

      



## start

```
minikube start --driver=none \
  --kubernetes-version=v1.23.10  \
  --extra-config=apiserver.service-account-signing-key-file=/var/lib/minikube/certs/sa.key \
  --extra-config=apiserver.service-account-issuer=kubernetes.default.svc
```



### access dashboard

- port-forward 

  ```
  $ kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
  ```

  > ```
  > localhost:8080
  > ```

- port access

  ```
  $ minikube service list -n istio-system
  ```

  ```
  |--------------|-----------------------|-------------------|----------------------------|
  |  NAMESPACE   |         NAME          |    TARGET PORT    |            URL             |
  |--------------|-----------------------|-------------------|----------------------------|
  | istio-system | authservice           | No node port      |
  | istio-system | cluster-local-gateway | No node port      |
  | istio-system | istio-ingressgateway  | status-port/15021 | http://192.168.0.107:31478 |
  |              |                       | http2/80          | http://192.168.0.107:31355 |
  |              |                       | https/443         | http://192.168.0.107:30779 |
  |              |                       | tcp/31400         | http://192.168.0.107:31354 |
  |              |                       | tls/15443         | http://192.168.0.107:31375 |
  | istio-system | istiod                | No node port      |
  | istio-system | knative-local-gateway | No node port      |
  |--------------|-----------------------|-------------------|----------------------------|
  ```

  ìœ„ ì¤‘ `istio-ingressgateway ` -`http2/80` ì˜ URL

  ```
  http://192.168.0.107:31355
  ```

  



### access from outside 

#### ngrok

**install** 

```
$ sudo snap install ngrok
```



**using**

> ```
> $  kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
> ```
>
> ìœ„ ëª…ë ¹ì–´ê°€ í™œì„±í™” ëœ terminalì´ ì—´ë ¤ìˆì–´ì•¼ í•¨ 

```
$ ngrok http 8080
```

```
ngrok by @inconshreveable                                                                                                                                           (Ctrl+C to quit)

Session Status                online
Session Expires               1 hour, 51 minutes
Version                       2.3.40
Region                        United States (us)
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://eb45-1-214-32-67.ngrok.io -> http://localhost:8090

Connections                   ttl     opn     rt1     rt5     p50     p90
                              2       0       0.00    0.00    300.58  300.92

HTTP Requests
-------------

GET /favicon.ico               302 Found
GET /                          302 Found
GET /                          302 Found
```

- `Session Status` : sessionì˜ ìƒíƒœ. onlineì¼ ê²½ìš° ì •ìƒ

- `Session Expires` : ë‚¨ì€ sessionì˜ ë§Œë£Œ ì‹œê°„

  > ë§Œë£Œ ì‹œê°„ì´ ì§€ë‚˜ë©´ ë‹¤ì‹œ `./ngrok http {port}`ëª…ë ¹ì–´ ì…ë ¥í•´ì•¼í•¨
  >
  > ë§Œë£Œ ì‹œê°„ ì—†ì´ ì‚¬ìš©í•˜ë ¤ë©´ ê³„ì • ì—°ë™. ë°©ë²•ì€ ì•„ë˜ì—

- `Region` : ngrok agentê°€ ternalì„ hotingí•˜ê¸° ìœ„í•œ region

- `Web Interface` : ngrok dashboardë¥¼ ì œê³µí•˜ëŠ” URL

- `Forwarding` : ngrokì—ì„œ ì œê³µí•˜ëŠ” ternal URLë¡œ, ì´ë¥¼ í†µí•´ ì™¸ë¶€ì—ì„œë„ local í•œê²½ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. (http, httpsì œê³µ)





**account linking**

[ê³µì‹ í˜ì´ì§€](https://ngrok.com/) ì— ë¡œê·¸ì¸ í›„  `Your Authtoken`ì—ì„œ tokenë°›ê³  ì•„ë˜ ëª…ë ¹ì–´

```
$ ngrok config add-authtoken {tokenê°’}
```



> remove
>
> ```
> $ sudo snap remove ngrok
> ```
>



#### External-IP

**istio-ingressgateway ì˜ spec.typeì´ `LoadBalancer` ì„ì„ í™•ì¸**

`nodeport`ë¼ ë˜ì–´ìˆìœ¼ë©´ ë³€ê²½ í•„ìš”

```
$ kubectl edit service -n istio-system istio-ingressgateway
```



1. **get `External-IP`** 

   ì•„ì§ì€ `External-IP`ì´ `<pending> `ì¼ ê²ƒì„

   ```
   $ kubectl get service -n istio-system istio-ingressgateway
   ```

   ```
   NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                      AGE
   istio-ingressgateway   LoadBalancer   10.110.207.155   <pending>     15021:31478/TCP,80:31355/TCP,443:30779/TCP,31400:31354/TCP,15443:31375/TCP   48m
   ```

   1. enable **MetalLB**

      minikubeì˜ addonsì¤‘ `metallb ` í™•ì¸

      ```
      $ minikube addons list
      ```

      ```
      | metallb                     | minikube | disabled     | 3rd party (MetalLB)            |
      ```

      

      enable `metallb`

      ```
      $ minikube addons enable metallb
      ```

      ```
      â—  metallb is a 3rd party addon and not maintained or verified by minikube maintainers, enable at your own risk.
          â–ª Using image metallb/speaker:v0.9.6
          â–ª Using image metallb/controller:v0.9.6
      ğŸŒŸ  The 'metallb' addon is enabled
      ```

      

   2. set IP range

      ```
      $ minikube addons configure metallb
      ```

      ```
      -- Enter Load Balancer Start IP: 192.168.0.240
      -- Enter Load Balancer End IP: 192.168.0.249
          â–ª Using image metallb/speaker:v0.9.6
          â–ª Using image metallb/controller:v0.9.6
      âœ…  metallb was successfully configured
      ```

      - `-- Enter Load Balancer Start IP` ,` -- Enter Load Balancer End IP` : **192.168.0.240** ë¶€í„° **192.168.0.249** ì‚¬ì´ì˜ Host IPì£¼ì†Œ í• ë‹¹

        > ë„ˆë¬´ ë§ì´ í• ë‹¹í•˜ë©´ ê¸°ì¡´ì— íšŒì‚¬ì—ì„œ ì‚¬ì„¤ IPë¥¼ ë°›ì•„ ì“°ë˜ ë‚´ë¶€ë§ clientë“¤ê³¼ ì¶©ëŒì´ ìˆì„ ìš°ë ¤ê°€ ìƒê¸°ë¯€ë¡œ ì¡°ì‹¬
        
        ```
        -- Enter Load Balancer Start IP: 192.168.0.240
        -- Enter Load Balancer End IP: 192.168.0.249
        ```
        
        

      

   3. check `EXTERNAL-IP`

      ```
      $ kubectl get service -n istio-system istio-ingressgateway
      ```

      ```
      NAME                   TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                                                                      AGE
      istio-ingressgateway   LoadBalancer   10.110.207.155   192.168.0.240   15021:31478/TCP,80:31355/TCP,443:30779/TCP,31400:31354/TCP,15443:31375/TCP   54m
      ```

      `192.168.0.240` ì˜ ì™¸ë¶€ IPê°€ ìƒê²¼ìŒì„ í™•ì¸

   

2. **access from client**

   1. configure port poward

      iptime ê³µìœ ê¸° ì‚¬ìš© ì¤‘ì´ë©´ `192.168.0.1` ì ‘ì† í›„

      `ê´€ë¦¬ë„êµ¬ - ë„¤ì´ê²Œì´ì…˜ì˜ ê³ ê¸‰ ì„¤ì • - NAT/ë¼ìš°í„° ê´€ë¦¬  - í¬íŠ¸í¬ì›Œë“œ ì„¤ì •`

      **ìƒˆ ê·œì¹™ ì¶”ê°€**

      ```
      ë‚´ë¶€ IP : 192.168.0.107
      
      ì™¸ë¶€ í¬íŠ¸ : 2222
      
      ë‚´ë¶€ í¬íŠ¸ : 22
      ```

      > ì™¸ë¶€ IPì˜ port 2222ë¡œ ì ‘ì†í•˜ë©´ ë‚´ë¶€ IPì˜ ë‚´ë¶€ port 22ë¡œ ì ‘ì†ì´ ë˜ê²Œ ì„¤ì •

   2. access from client

      client terminalì—ì„œ 

      ```
      ssh -L {ì™¸ë¶€ port}:{istio-ingressgatewa ì˜ EXTERNAL-IP}:80 {ì ‘ì†í•˜ê³ ì í•˜ëŠ” ì„œë²„ì˜ ID}@{ì™¸ë¶€ IP} -p {ì™¸ë¶€ port}
      ```

      > ì˜ˆì‹œ
      >
      > ```
      > ssh -L 2222:192.168.0.240:80 ainsoft@x.xxx.xx.xx -p 2222
      > ```

      ì´ì œ í•´ë‹¹ terminalì´ ì—´ë ¤ìˆëŠ” ìƒíƒœì—ì„œ

      browserì— `http://localhost:2222` ì…ë ¥ ì‹œ kubeflow dashboardì‚¬ìš© ì‚¬ëŠ¥

   





## uninstall



1. delete docker container

   ```
   $ docker rm -f $(docker ps -aq)
   ```

2. delete docker images

   ```
   $ docker rmi $(docker images -q)
   ```

3. delete minikube

   ```
   $ minikube stop
   $ minikube delete
   ```

   > minikubeë¥¼ í†µí•´ ì‹¤í–‰ë˜ë˜ clusterë¥¼ ì‚­ì œ. minikubeìì²´ë¥¼ ì‚­ì œí•œê²ƒì´ ì•„ë‹˜.
   >
   > error
   >
   > - `env: â€˜kubeadmâ€™: No such file or directory`
   >
   >   ì´ëŸ° ê²½ìš° minikubeì˜ prifilesë¥¼ ì „ë¶€ ì‚­ì œ
   >
   >   ```
   >   $ sudo rm -rf ~/.kube ~/.minikube
   >   ```

4. delete kubectl 

   `kubectl`, `kubectl.sha256` ê°€ ìˆëŠ” ìœ„ì¹˜ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´

   ```
   $ rm -rf kubectl
   $ rm -rf kubectl.sha256
   ```

   ì´í›„ ì•„ë˜ ëª…ë ¹ì–´

   ```
   $ sudo rm /usr/local/bin/kubectl
   ```

   

